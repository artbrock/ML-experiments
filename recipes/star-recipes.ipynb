{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the environment and various imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (1.26.3)\n",
      "Requirement already satisfied: pandas in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: torch in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: tensorflow in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (2.15.0.post1)\n",
      "Requirement already satisfied: tensorflow_hub in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (0.16.1)\n",
      "Requirement already satisfied: torch-optim in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (0.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: filelock in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (0.35.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (1.60.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow_hub) (2.15.0)\n",
      "Requirement already satisfied: deap>=1.3.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch-optim) (1.4.1)\n",
      "Requirement already satisfied: pytorch-ignite>=0.4.8 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch-optim) (0.4.13)\n",
      "Requirement already satisfied: thop>=0.0.31 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch-optim) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch-pruning>=0.2.7 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch-optim) (1.3.6)\n",
      "Requirement already satisfied: torchvision>=0.11.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch-optim) (0.17.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torchvision>=0.11.1->torch-optim) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from jinja2->torch) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas torch tensorflow tensorflow_hub torch-optim\n",
    "# !pip install  nltk pandas matplotlib==3.8.2 sklearn\n",
    "# !pip install torchinfo torchvision==0.16.2 torchtext==0.7.0\n",
    "# !pip install python-dotenv psycopg2-binary wandb pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30793/2701461441.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-02-01 17:54:44.733029: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-01 17:54:44.733063: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-01 17:54:44.734308: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-01 17:54:44.740858: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-01 17:54:45.706606: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor, nn, optim, relu, sigmoid, tanh, softmax, log_softmax\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "# from typing import List, Tuple, Dict, Any\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Pre-Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directions</th>\n",
       "      <th>fat</th>\n",
       "      <th>date</th>\n",
       "      <th>categories</th>\n",
       "      <th>calories</th>\n",
       "      <th>desc</th>\n",
       "      <th>protein</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1. Place the stock, lentils, celery, carrot, ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2006-09-01 04:00:00+00:00</td>\n",
       "      <td>[Sandwich, Bean, Fruit, Tomato, turkey, Vegeta...</td>\n",
       "      <td>426.0</td>\n",
       "      <td>None</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.500</td>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>[4 cups low-sodium vegetable or chicken stock,...</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Combine first 9 ingredients in heavy medium s...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2004-08-20 04:00:00+00:00</td>\n",
       "      <td>[Food Processor, Onion, Pork, Bake, Bastille D...</td>\n",
       "      <td>403.0</td>\n",
       "      <td>This uses the same ingredients found in boudin...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.375</td>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>[1 1/2 cups whipping cream, 2 medium onions, c...</td>\n",
       "      <td>1439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In a large heavy saucepan cook diced fennel a...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2004-08-20 04:00:00+00:00</td>\n",
       "      <td>[Soup/Stew, Dairy, Potato, Vegetable, Fennel, ...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>None</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.750</td>\n",
       "      <td>Potato and Fennel Soup Hodge</td>\n",
       "      <td>[1 fennel bulb (sometimes called anise), stalk...</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Heat oil in heavy large skillet over medium-h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-03-27 04:00:00+00:00</td>\n",
       "      <td>[Fish, Olive, Tomato, Sauté, Low Fat, Low Cal,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sicilian-style tomato sauce has tons of Me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000</td>\n",
       "      <td>Mahi-Mahi in Tomato Olive Sauce</td>\n",
       "      <td>[2 tablespoons extra-virgin olive oil, 1 cup c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Preheat oven to 350°F. Lightly grease 8x8x2-i...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2004-08-20 04:00:00+00:00</td>\n",
       "      <td>[Cheese, Dairy, Pasta, Vegetable, Side, Bake, ...</td>\n",
       "      <td>547.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.125</td>\n",
       "      <td>Spinach Noodle Casserole</td>\n",
       "      <td>[1 12-ounce package frozen spinach soufflé, th...</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          directions   fat  \\\n",
       "0  [1. Place the stock, lentils, celery, carrot, ...   7.0   \n",
       "1  [Combine first 9 ingredients in heavy medium s...  23.0   \n",
       "2  [In a large heavy saucepan cook diced fennel a...   7.0   \n",
       "3  [Heat oil in heavy large skillet over medium-h...   NaN   \n",
       "4  [Preheat oven to 350°F. Lightly grease 8x8x2-i...  32.0   \n",
       "\n",
       "                       date  \\\n",
       "0 2006-09-01 04:00:00+00:00   \n",
       "1 2004-08-20 04:00:00+00:00   \n",
       "2 2004-08-20 04:00:00+00:00   \n",
       "3 2009-03-27 04:00:00+00:00   \n",
       "4 2004-08-20 04:00:00+00:00   \n",
       "\n",
       "                                          categories  calories  \\\n",
       "0  [Sandwich, Bean, Fruit, Tomato, turkey, Vegeta...     426.0   \n",
       "1  [Food Processor, Onion, Pork, Bake, Bastille D...     403.0   \n",
       "2  [Soup/Stew, Dairy, Potato, Vegetable, Fennel, ...     165.0   \n",
       "3  [Fish, Olive, Tomato, Sauté, Low Fat, Low Cal,...       NaN   \n",
       "4  [Cheese, Dairy, Pasta, Vegetable, Side, Bake, ...     547.0   \n",
       "\n",
       "                                                desc  protein  rating  \\\n",
       "0                                               None     30.0   2.500   \n",
       "1  This uses the same ingredients found in boudin...     18.0   4.375   \n",
       "2                                               None      6.0   3.750   \n",
       "3  The Sicilian-style tomato sauce has tons of Me...      NaN   5.000   \n",
       "4                                               None     20.0   3.125   \n",
       "\n",
       "                                         title  \\\n",
       "0              Lentil, Apple, and Turkey Wrap    \n",
       "1  Boudin Blanc Terrine with Red Onion Confit    \n",
       "2                Potato and Fennel Soup Hodge    \n",
       "3             Mahi-Mahi in Tomato Olive Sauce    \n",
       "4                    Spinach Noodle Casserole    \n",
       "\n",
       "                                         ingredients  sodium  \n",
       "0  [4 cups low-sodium vegetable or chicken stock,...   559.0  \n",
       "1  [1 1/2 cups whipping cream, 2 medium onions, c...  1439.0  \n",
       "2  [1 fennel bulb (sometimes called anise), stalk...   165.0  \n",
       "3  [2 tablespoons extra-virgin olive oil, 1 cup c...     NaN  \n",
       "4  [1 12-ounce package frozen spinach soufflé, th...   452.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON_FILE = \"./dataset/full_format_recipes.json\"\n",
    "dataset = pd.read_json(JSON_FILE)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>None</td>\n",
       "      <td>[4 cups low-sodium vegetable or chicken stock,...</td>\n",
       "      <td>[1. Place the stock, lentils, celery, carrot, ...</td>\n",
       "      <td>2.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>This uses the same ingredients found in boudin...</td>\n",
       "      <td>[1 1/2 cups whipping cream, 2 medium onions, c...</td>\n",
       "      <td>[Combine first 9 ingredients in heavy medium s...</td>\n",
       "      <td>4.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Potato and Fennel Soup Hodge</td>\n",
       "      <td>None</td>\n",
       "      <td>[1 fennel bulb (sometimes called anise), stalk...</td>\n",
       "      <td>[In a large heavy saucepan cook diced fennel a...</td>\n",
       "      <td>3.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahi-Mahi in Tomato Olive Sauce</td>\n",
       "      <td>The Sicilian-style tomato sauce has tons of Me...</td>\n",
       "      <td>[2 tablespoons extra-virgin olive oil, 1 cup c...</td>\n",
       "      <td>[Heat oil in heavy large skillet over medium-h...</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spinach Noodle Casserole</td>\n",
       "      <td>None</td>\n",
       "      <td>[1 12-ounce package frozen spinach soufflé, th...</td>\n",
       "      <td>[Preheat oven to 350°F. Lightly grease 8x8x2-i...</td>\n",
       "      <td>3.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0              Lentil, Apple, and Turkey Wrap    \n",
       "1  Boudin Blanc Terrine with Red Onion Confit    \n",
       "2                Potato and Fennel Soup Hodge    \n",
       "3             Mahi-Mahi in Tomato Olive Sauce    \n",
       "4                    Spinach Noodle Casserole    \n",
       "\n",
       "                                         description  \\\n",
       "0                                               None   \n",
       "1  This uses the same ingredients found in boudin...   \n",
       "2                                               None   \n",
       "3  The Sicilian-style tomato sauce has tons of Me...   \n",
       "4                                               None   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  [4 cups low-sodium vegetable or chicken stock,...   \n",
       "1  [1 1/2 cups whipping cream, 2 medium onions, c...   \n",
       "2  [1 fennel bulb (sometimes called anise), stalk...   \n",
       "3  [2 tablespoons extra-virgin olive oil, 1 cup c...   \n",
       "4  [1 12-ounce package frozen spinach soufflé, th...   \n",
       "\n",
       "                                          directions  rating  \n",
       "0  [1. Place the stock, lentils, celery, carrot, ...   2.500  \n",
       "1  [Combine first 9 ingredients in heavy medium s...   4.375  \n",
       "2  [In a large heavy saucepan cook diced fennel a...   3.750  \n",
       "3  [Heat oil in heavy large skillet over medium-h...   5.000  \n",
       "4  [Preheat oven to 350°F. Lightly grease 8x8x2-i...   3.125  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Drop the columns that are not needed\n",
    "dataset = dataset.drop(columns=['date', 'categories', 'calories', 'protein', 'fat', 'sodium'])\n",
    "## Resequence the columns\n",
    "dataset = dataset.reindex(columns=['title', 'desc', 'ingredients', 'directions', 'rating'])\n",
    "## Rename desc to description\n",
    "dataset = dataset.rename(columns={'desc': 'description'})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing directions 19\n",
      "missing ingredients 0\n",
      "missing ratings 11\n"
     ]
    }
   ],
   "source": [
    "## Remove rows with missing values\n",
    "print(\"missing directions\", dataset['directions'].isnull().sum())\n",
    "dataset = dataset[dataset['directions'].notna()]\n",
    "print(\"missing ingredients\", dataset['ingredients'].isnull().sum())\n",
    "dataset = dataset[dataset['ingredients'].notna()]\n",
    "print(\"missing ratings\", dataset['rating'].isna().sum())\n",
    "dataset = dataset[dataset['rating'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Rating Average 3.7130597014925373\n",
      "Original deviation 1.3431435358354373\n",
      "\n",
      "Average rating 0.7426119402985074\n",
      "Standard deviation 0.2686287071670875\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Rating Average\", dataset['rating'].mean())\n",
    "print(\"Original deviation\", dataset['rating'].std())\n",
    "## Normalize the ratings between 0 and 1\n",
    "if dataset['rating'].mean() > 1.0:\n",
    "       dataset['rating'] = dataset['rating'] / 5.0\n",
    "print(\"\\nAverage rating\", dataset['rating'].mean())\n",
    "print(\"Standard deviation\", dataset['rating'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare dataset for embedding\n",
    "\n",
    "## Where description is None, replace with the text \"No description\"\n",
    "dataset['description'] = dataset['description'].fillna('No description')\n",
    "\n",
    "## Join elements in the ingredients and directions columns with newlines between each element\n",
    "dataset['ingredients'] = dataset['ingredients'].apply(lambda x: ',\\n'.join(x))\n",
    "dataset['directions'] = dataset['directions'].apply(lambda x: '\\n'.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Lentil, Apple, and Turkey Wrap  \n",
      "Description: No description \n",
      "Ingredients: 4 cups low-sodium vegetable or chicken stock,\n",
      "1 cup dried brown lentils,\n",
      "1/2 cup dried French green lentils,\n",
      "2 stalks celery, chopped,\n",
      "1 large carrot, peeled and chopped,\n",
      "1 sprig fresh thyme,\n",
      "1 teaspoon kosher salt,\n",
      "1 medium tomato, cored, seeded, and diced,\n",
      "1 small Fuji apple, cored and diced,\n",
      "1 tablespoon freshly squeezed lemon juice,\n",
      "2 teaspoons extra-virgin olive oil,\n",
      "Freshly ground black pepper to taste,\n",
      "3 sheets whole-wheat lavash, cut in half crosswise, or 6 (12-inch) flour tortillas,\n",
      "3/4 pound turkey breast, thinly sliced,\n",
      "1/2 head Bibb lettuce \n",
      "Instructions: 1. Place the stock, lentils, celery, carrot, thyme, and salt in a medium saucepan and bring to a boil. Reduce heat to low and simmer until the lentils are tender, about 30 minutes, depending on the lentils. (If they begin to dry out, add water as needed.) Remove and discard the thyme. Drain and transfer the mixture to a bowl; let cool.\n",
      "2. Fold in the tomato, apple, lemon juice, and olive oil. Season with the pepper.\n",
      "3. To assemble a wrap, place 1 lavash sheet on a clean work surface. Spread some of the lentil mixture on the end nearest you, leaving a 1-inch border. Top with several slices of turkey, then some of the lettuce. Roll up the lavash, slice crosswise, and serve. If using tortillas, spread the lentils in the center, top with the turkey and lettuce, and fold up the bottom, left side, and right side before rolling away from you.\n"
     ]
    }
   ],
   "source": [
    "## Preview the data before running embedder\n",
    "print(f\"Title: {dataset['title'][0]} \\nDescription: {dataset['description'][0]} \\nIngredients: {dataset['ingredients'][0]} \\nInstructions: {dataset['directions'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arthur abandoned attempt to get Nvidia GPU working\n",
    "For future reference and troubleshooting... After I ran the following command and rebooted. I lost all access to KDE/Plasma GUI for Kubuntu and could only use the text only terminals via fn-ctrl-alt-f2\n",
    "\n",
    "```\n",
    "> sudo prime-select nvidia\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Set the device to run on: GPU, MPS, or CPU\n",
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 20100\n",
      "Train size: 15276\n",
      "Test size: 2412\n",
      "Val size: 2412\n"
     ]
    }
   ],
   "source": [
    "# 76% of processed_dataset is used for training\n",
    "train_size = int(0.76 * len(dataset))\n",
    "# 12% of clean_data is used for validation\n",
    "val_size = int(0.12 * len(dataset))\n",
    "# The remaining 12% is used for testing\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(\n",
    "   dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "print(f\"Total size: {len(dataset)}\")\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Test size: {len(test_data)}\")\n",
    "print(f\"Val size: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Universal Sentence Encoder Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 17:54:51.462000: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-02-01 17:55:04.900224: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1952573440 exceeds 10% of free system memory.\n",
      "2024-02-01 17:55:22.266414: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5732029440 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([2412, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create embeddings for the title, description, ingredients and directions\n",
    "## Use the Universal Sentence Encoder from Tensorflow Hub\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "train_title_embeddings = embed(dataset['title'][:train_size])\n",
    "train_description_embeddings = embed(dataset['description'][:train_size])\n",
    "train_ingredients_embeddings = embed(dataset['ingredients'][:train_size])\n",
    "train_directions_embeddings = embed(dataset['directions'][:train_size])\n",
    "\n",
    "train_title_embeddings.shape\n",
    "\n",
    "val_title_embeddings = embed(dataset['title'][train_size:train_size + val_size])\n",
    "val_description_embeddings = embed(dataset['description'][train_size:train_size + val_size])\n",
    "val_ingredients_embeddings = embed(dataset['ingredients'][train_size:train_size + val_size])\n",
    "val_directions_embeddings = embed(dataset['directions'][train_size:train_size + val_size])\n",
    "\n",
    "val_title_embeddings.shape\n",
    "\n",
    "test_title_embeddings = embed(dataset['title'][train_size + val_size:])\n",
    "test_description_embeddings = embed(dataset['description'][train_size + val_size:])\n",
    "test_ingredients_embeddings = embed(dataset['ingredients'][train_size + val_size:])\n",
    "test_directions_embeddings = embed(dataset['directions'][train_size + val_size:])\n",
    "\n",
    "test_title_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "train_title_embeddings = torch.from_numpy(train_title_embeddings.numpy())\n",
    "train_description_embeddings = torch.from_numpy(train_description_embeddings.numpy())\n",
    "train_ingredients_embeddings = torch.from_numpy(train_ingredients_embeddings.numpy())\n",
    "train_directions_embeddings = torch.from_numpy(train_directions_embeddings.numpy())\n",
    "train_ratings = torch.from_numpy(dataset['rating'][:train_size].values)\n",
    "\n",
    "val_title_embeddings = torch.from_numpy(val_title_embeddings.numpy())\n",
    "val_description_embeddings = torch.from_numpy(val_description_embeddings.numpy())\n",
    "val_ingredients_embeddings = torch.from_numpy(val_ingredients_embeddings.numpy())\n",
    "val_directions_embeddings = torch.from_numpy(val_directions_embeddings.numpy())\n",
    "val_ratings = torch.from_numpy(dataset['rating'][train_size:train_size+val_size].values)\n",
    "\n",
    "test_title_embeddings = torch.from_numpy(test_title_embeddings.numpy())\n",
    "test_description_embeddings = torch.from_numpy(test_description_embeddings.numpy())\n",
    "test_ingredients_embeddings = torch.from_numpy(test_ingredients_embeddings.numpy())\n",
    "test_directions_embeddings = torch.from_numpy(test_directions_embeddings.numpy())\n",
    "test_ratings = torch.from_numpy(dataset['rating'][train_size + val_size:].values)\n",
    "\n",
    "## Concatenate text embeddings and add ratings to create a pytorch dataset\n",
    "# Concatenate embeddings along the second dimension\n",
    "train_embeddings = torch.cat((train_title_embeddings, train_description_embeddings, train_ingredients_embeddings, train_directions_embeddings), dim=1)\n",
    "val_embeddings = torch.cat((val_title_embeddings, val_description_embeddings, val_ingredients_embeddings, val_directions_embeddings), dim=1)\n",
    "test_embeddings = torch.cat((test_title_embeddings, test_description_embeddings, test_ingredients_embeddings, test_directions_embeddings), dim=1)\n",
    "\n",
    "# Create a TensorDatasets\n",
    "train_dataset = TensorDataset(train_embeddings, train_ratings)\n",
    "val_dataset = TensorDataset(val_embeddings, val_ratings)\n",
    "test_dataset = TensorDataset(test_embeddings, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataset class\n",
    "\n",
    "# class RecipeDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, title_embeddings, description_embeddings, ingredients_embeddings, directions_embeddings, ratings):\n",
    "#         self.title_embeddings = title_embeddings\n",
    "#         self.description_embeddings = description_embeddings\n",
    "#         self.ingredients_embeddings = ingredients_embeddings\n",
    "#         self.directions_embeddings = directions_embeddings\n",
    "#         self.ratings = ratings\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.title_embeddings)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return (\n",
    "#             self.title_embeddings[idx],\n",
    "#             self.description_embeddings[idx],\n",
    "#             self.ingredients_embeddings[idx],\n",
    "#             self.directions_embeddings[idx],\n",
    "#             self.ratings[idx],\n",
    "#         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecipeRatingsPredictor(\n",
      "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Create a PyTorch model to predict the ratings using the four embeddings as inputs\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "class RecipeRatingsPredictor(nn.Module):\n",
    "## The model will have 4 fully connected layers with ReLU activation functions\n",
    "##    and a final output layer with a sigmoid activation function\n",
    "    def __init__(self):\n",
    "        super(RecipeRatingsPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(512 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "## The model will also have a dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.dropout(torch.relu(self.fc3(x)))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "# Assuming train_dataset is your training dataset\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "## Create the dataloaders\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model, loss function and optimizer\n",
    "model = RecipeRatingsPredictor()\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.06441819667816162\n",
      "Epoch 2/10, Loss: 0.07595887035131454\n",
      "Epoch 3/10, Loss: 0.0790715143084526\n",
      "Epoch 4/10, Loss: 0.1062641590833664\n",
      "Epoch 5/10, Loss: 0.11737996339797974\n",
      "Epoch 6/10, Loss: 0.06871405243873596\n",
      "Epoch 7/10, Loss: 0.07605595141649246\n",
      "Epoch 8/10, Loss: 0.09824790060520172\n",
      "Epoch 9/10, Loss: 0.1161341443657875\n",
      "Epoch 10/10, Loss: 0.0784933865070343\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations for Tuning Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize spread of activation values in the nn layers\n",
    "\n",
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i, layer in enumerate(layers[:-1]): # note: exclude the output layer\n",
    "  if isinstance(layer, Tanh):\n",
    "    t = layer.out\n",
    "    print('layer %d (%10s): mean %+.2f, std %.2f, saturated: %.2f%%' % (i, layer.__class__.__name__, t.mean(), t.std(), (t.abs() > 0.97).float().mean()*100))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'layer {i} ({layer.__class__.__name__}')\n",
    "plt.legend(legends);\n",
    "plt.title('activation distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize deviation gradients of values in the nn layers\n",
    "\n",
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i, layer in enumerate(layers[:-1]): # note: exclude the output layer\n",
    "  if isinstance(layer, Tanh):\n",
    "    t = layer.out.grad\n",
    "    print('layer %d (%10s): mean %+f, std %e' % (i, layer.__class__.__name__, t.mean(), t.std()))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'layer {i} ({layer.__class__.__name__}')\n",
    "plt.legend(legends);\n",
    "plt.title('gradient distribution')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize distribution of weights in the nn layers\n",
    "\n",
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i,p in enumerate(parameters):\n",
    "  t = p.grad\n",
    "  if p.ndim == 2:\n",
    "    print('weight %10s | mean %+f | std %e | grad:data ratio %e' % (tuple(p.shape), t.mean(), t.std(), t.std() / p.std()))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'{i} {tuple(p.shape)}')\n",
    "plt.legend(legends)\n",
    "plt.title('weights gradient distribution');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the ratio of gradients to data in the nn layers (learning rate should land this near ~.003)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "for i,p in enumerate(parameters):\n",
    "  if p.ndim == 2:\n",
    "    plt.plot([ud[j][i] for j in range(len(ud))])\n",
    "    legends.append('param %d' % i)\n",
    "plt.plot([0, len(ud)], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "plt.legend(legends);\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recipes-lGug3pN3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
