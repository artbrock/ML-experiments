{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux ACB-TPX1X-G3 5.15.0-92-generic #102-Ubuntu SMP Wed Jan 10 09:33:48 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux\n"
     ]
    }
   ],
   "source": [
    "!uname -a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (1.8.0)\n",
      "Requirement already satisfied: matplotlib==3.8.2 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (3.8.2)\n",
      "Requirement already satisfied: torch==2.1.2 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: torchvision==0.16.2 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (0.16.2)\n",
      "Requirement already satisfied: numpy in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (1.26.3)\n",
      "Requirement already satisfied: pandas in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: python-dotenv in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: tensorflow_hub in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (0.16.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from matplotlib==3.8.2) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from matplotlib==3.8.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from matplotlib==3.8.2) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from matplotlib==3.8.2) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from matplotlib==3.8.2) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from matplotlib==3.8.2) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from matplotlib==3.8.2) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from matplotlib==3.8.2) (2.8.2)\n",
      "Requirement already satisfied: filelock in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (1.12)\n",
      "Requirement already satisfied: networkx in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torch==2.1.2) (2.1.0)\n",
      "Requirement already satisfied: requests in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from torchvision==0.16.2) (2.31.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2) (12.3.101)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow_hub) (4.23.4)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from tensorflow_hub) (2.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib==3.8.2) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from jinja2->torch==2.1.2) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from requests->torchvision==0.16.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from requests->torchvision==0.16.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from requests->torchvision==0.16.2) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from requests->torchvision==0.16.2) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/artbrock/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages (from sympy->torch==2.1.2) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install torchinfo matplotlib==3.8.2 torch==2.1.2 torchvision==0.16.2 numpy pandas python-dotenv tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49640/4177980191.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-02-02 10:28:09.268268: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-02 10:28:09.268326: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-02 10:28:09.293850: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-02 10:28:09.346738: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-02 10:28:10.716443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-02-02 10:28:14.519465: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # (i.e. \"neural network\")\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "USE = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directions</th>\n",
       "      <th>fat</th>\n",
       "      <th>date</th>\n",
       "      <th>categories</th>\n",
       "      <th>calories</th>\n",
       "      <th>desc</th>\n",
       "      <th>protein</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1. Place the stock, lentils, celery, carrot, ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2006-09-01 04:00:00+00:00</td>\n",
       "      <td>[Sandwich, Bean, Fruit, Tomato, turkey, Vegeta...</td>\n",
       "      <td>426.0</td>\n",
       "      <td>None</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.500</td>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>[4 cups low-sodium vegetable or chicken stock,...</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Combine first 9 ingredients in heavy medium s...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2004-08-20 04:00:00+00:00</td>\n",
       "      <td>[Food Processor, Onion, Pork, Bake, Bastille D...</td>\n",
       "      <td>403.0</td>\n",
       "      <td>This uses the same ingredients found in boudin...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.375</td>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>[1 1/2 cups whipping cream, 2 medium onions, c...</td>\n",
       "      <td>1439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In a large heavy saucepan cook diced fennel a...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2004-08-20 04:00:00+00:00</td>\n",
       "      <td>[Soup/Stew, Dairy, Potato, Vegetable, Fennel, ...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>None</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.750</td>\n",
       "      <td>Potato and Fennel Soup Hodge</td>\n",
       "      <td>[1 fennel bulb (sometimes called anise), stalk...</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Heat oil in heavy large skillet over medium-h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-03-27 04:00:00+00:00</td>\n",
       "      <td>[Fish, Olive, Tomato, Sauté, Low Fat, Low Cal,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sicilian-style tomato sauce has tons of Me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000</td>\n",
       "      <td>Mahi-Mahi in Tomato Olive Sauce</td>\n",
       "      <td>[2 tablespoons extra-virgin olive oil, 1 cup c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Preheat oven to 350°F. Lightly grease 8x8x2-i...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2004-08-20 04:00:00+00:00</td>\n",
       "      <td>[Cheese, Dairy, Pasta, Vegetable, Side, Bake, ...</td>\n",
       "      <td>547.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.125</td>\n",
       "      <td>Spinach Noodle Casserole</td>\n",
       "      <td>[1 12-ounce package frozen spinach soufflé, th...</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          directions   fat  \\\n",
       "0  [1. Place the stock, lentils, celery, carrot, ...   7.0   \n",
       "1  [Combine first 9 ingredients in heavy medium s...  23.0   \n",
       "2  [In a large heavy saucepan cook diced fennel a...   7.0   \n",
       "3  [Heat oil in heavy large skillet over medium-h...   NaN   \n",
       "4  [Preheat oven to 350°F. Lightly grease 8x8x2-i...  32.0   \n",
       "\n",
       "                       date  \\\n",
       "0 2006-09-01 04:00:00+00:00   \n",
       "1 2004-08-20 04:00:00+00:00   \n",
       "2 2004-08-20 04:00:00+00:00   \n",
       "3 2009-03-27 04:00:00+00:00   \n",
       "4 2004-08-20 04:00:00+00:00   \n",
       "\n",
       "                                          categories  calories  \\\n",
       "0  [Sandwich, Bean, Fruit, Tomato, turkey, Vegeta...     426.0   \n",
       "1  [Food Processor, Onion, Pork, Bake, Bastille D...     403.0   \n",
       "2  [Soup/Stew, Dairy, Potato, Vegetable, Fennel, ...     165.0   \n",
       "3  [Fish, Olive, Tomato, Sauté, Low Fat, Low Cal,...       NaN   \n",
       "4  [Cheese, Dairy, Pasta, Vegetable, Side, Bake, ...     547.0   \n",
       "\n",
       "                                                desc  protein  rating  \\\n",
       "0                                               None     30.0   2.500   \n",
       "1  This uses the same ingredients found in boudin...     18.0   4.375   \n",
       "2                                               None      6.0   3.750   \n",
       "3  The Sicilian-style tomato sauce has tons of Me...      NaN   5.000   \n",
       "4                                               None     20.0   3.125   \n",
       "\n",
       "                                         title  \\\n",
       "0              Lentil, Apple, and Turkey Wrap    \n",
       "1  Boudin Blanc Terrine with Red Onion Confit    \n",
       "2                Potato and Fennel Soup Hodge    \n",
       "3             Mahi-Mahi in Tomato Olive Sauce    \n",
       "4                    Spinach Noodle Casserole    \n",
       "\n",
       "                                         ingredients  sodium  \n",
       "0  [4 cups low-sodium vegetable or chicken stock,...   559.0  \n",
       "1  [1 1/2 cups whipping cream, 2 medium onions, c...  1439.0  \n",
       "2  [1 fennel bulb (sometimes called anise), stalk...   165.0  \n",
       "3  [2 tablespoons extra-virgin olive oil, 1 cup c...     NaN  \n",
       "4  [1 12-ounce package frozen spinach soufflé, th...   452.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON_FILE = \"./dataset/full_format_recipes.json\"\n",
    "dataset = pd.read_json(JSON_FILE)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing ingredients 0\n",
      "missing ratings 0\n",
      "missing directions 0\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset[dataset['directions'].notna()]\n",
    "dataset = dataset[dataset['rating'].notna()]\n",
    "print(\"missing ingredients\", dataset['ingredients'].isnull().sum())\n",
    "print(\"missing ratings\", dataset['rating'].isna().sum())\n",
    "print(\"missing directions\", dataset['directions'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m         recipe \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTITLE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDESCRIPTION: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mINGREDIENTS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mingredients\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mINSTRUCTIONS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(recipe)\n\u001b[0;32m---> 33\u001b[0m clean_data \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrameDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m, in \u001b[0;36mDataFrameDataset.__init__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5.0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecipe\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m recipe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecipe\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m good \u001b[38;5;241m=\u001b[39m recipe\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages/pandas/core/frame.py:10347\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10335\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10337\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10345\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10346\u001b[0m )\n\u001b[0;32m> 10347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/recipes-lGug3pN3/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m, in \u001b[0;36mDataFrameDataset.format\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     29\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirections\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirections\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m recipe \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTITLE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDESCRIPTION: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mINGREDIENTS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mingredients\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mINSTRUCTIONS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m, in \u001b[0;36mDataFrameDataset.embed\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     23\u001b[0m    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence):\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#       print(embedding = USE([sentence]))\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m        \u001b[38;5;28;01mreturn\u001b[39;00m  torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43membedding\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class DataFrameDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input):\n",
    "        self.dataframe = pd.DataFrame()\n",
    "        self.dataframe['rating'] = torch.tensor(input['rating'], dtype=torch.float) / 5.0\n",
    "        self.dataframe['recipe'] = input.apply(self.format, axis=1)\n",
    "\n",
    "        recipe = self.dataframe['recipe']\n",
    "        good = recipe.apply(lambda x: isinstance(x, torch.Tensor))\n",
    "        self.dataframe = self.dataframe[good]\n",
    "        \n",
    "        # non_tensors = self.dataframe['recipe'].map(lambda x: not isinstance(x, torch.Tensor))\n",
    "        # self.dataframe['recipe'] = self.dataframe['recipe'][non_tensors]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.dataframe.iloc[idx]['recipe']\n",
    "        label = self.dataframe.iloc[idx]['rating']\n",
    "        return torch.tensor(input, dtype=torch.float), torch.tensor([label], dtype=torch.float)\n",
    "\n",
    "    def embed(self, sentence):\n",
    "        print(embedding = USE([sentence]))\n",
    "        return  torch.from_numpy(embedding.numpy()).float().squeeze(0)\n",
    "\n",
    "    def format(self, data):\n",
    "        ingredients = \" \".join(data['ingredients']) if data['ingredients'] else \"\"\n",
    "        steps = \" \".join(data['directions']) if data['directions'] else \"\"\n",
    "        recipe = f\"TITLE: {data['title']} \\nDESCRIPTION: {data['desc']} \\nINGREDIENTS: {ingredients} \\nINSTRUCTIONS: {steps}\"\n",
    "        return self.embed(recipe)\n",
    "\n",
    "clean_data = DataFrameDataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = clean_data.dataframe['recipe']\n",
    "bad = recipe.apply(lambda x: not isinstance(x, torch.Tensor))\n",
    "print(recipe[bad].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% of processed_dataset is used for training\n",
    "train_size = int(0.76 * len(clean_data))\n",
    "# 15% of clean_data is used for validation\n",
    "val_size = int(0.12 * len(clean_data))\n",
    "# The remaining 15% is used for testing\n",
    "test_size = len(clean_data) - train_size - val_size\n",
    "\n",
    "\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(\n",
    "   clean_data, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "print(f\"Total size: {len(clean_data)}\")\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Test size: {len(test_data)}\")\n",
    "print(f\"Val size: {len(val_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StarModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StarModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass data through fc1\n",
    "        x = self.fc1(x)\n",
    "        # Use ReLU activation function\n",
    "        x = F.relu(x)\n",
    "        # Pass data through fc2\n",
    "        x = self.fc2(x)\n",
    "        # UsF.ReLU activation function\n",
    "        x = F.relu(x)\n",
    "        # Pass data through fc3\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_data))\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "# Number of epochs to train for\n",
    "epochs = 8\n",
    "\n",
    "\n",
    "# Create a DataLoader with batch size of 32\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Define a loss function - Mean Squared Error is used here as an example\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define an optimizer - Stochastic Gradient Descent is used here as an example\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "model = StarModel()\n",
    "model.to(device)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(epochs)\n",
    "loss_history = []\n",
    "for epoch in range(epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "\n",
    "        # print(inputs.shape, targets.shape)\n",
    "        # print(targets[0].shape)\n",
    "\n",
    "        # print(inputs, targets)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs.to(device))\n",
    "\n",
    "        # Calculate loss\n",
    "        # print(\"Pred min, max: \", outputs.shape, outputs.min().item(), outputs.max().item())\n",
    "        # print(\"Label min, max: \", targets.shape, targets.min().item(), targets.max().item())\n",
    "        loss = criterion(outputs, targets.to(device))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "# Plotting the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.title('Loss History')\n",
    "plt.xlabel('Batch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_loader(train_loader):\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        # Check if data and labels are of type torch.Tensor\n",
    "        assert isinstance(data, torch.Tensor), f\"Data in batch {i} is not a torch.Tensor\"\n",
    "        assert isinstance(labels, torch.Tensor), f\"Labels in batch {i} is not a torch.Tensor\"\n",
    "        \n",
    "        # Check the dimensions of the data and labels\n",
    "        # Assuming data should have dimensions [batch_size, 512] and labels [batch_size, 1]\n",
    "        assert data.dim() == 2, f\"Data in batch {i} does not have 2 dimensions\"\n",
    "        assert data.shape[1] == 512, f\"Data in batch {i} does not have 512 features, has {data.shape[1]}\"\n",
    "        assert labels.dim() == 2, f\"Labels in batch {i} do not have 2 dimensions\"\n",
    "        assert labels.shape[1] == 1, f\"Labels in batch {i} are not single values, shape is {labels.shape}\"\n",
    "        \n",
    "        # Optionally, check the range of data and labels if applicable\n",
    "        # For example, if labels are ratings between 0 and 5\n",
    "        assert labels.min() >= 0, f\"Labels in batch {i} contain values less than 0\"\n",
    "        assert labels.max() <= 1, f\"Labels in batch {i} contain values greater than 5\"\n",
    "        \n",
    "        print(f\"Batch {i} passed all tests.\")\n",
    "\n",
    "# Assuming train_loader is your DataLoader instance\n",
    "test_train_loader(train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the recipe embeddings via U.S.E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a visualization of the embeddings using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "recipes = clean_data.dataframe['recipe']\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(recipes.tolist())\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter([], [], c='blue', label='Recipes')\n",
    "plt.title('PCA plot of Recipe Embeddings')\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a random sample of Reddit texts to compare against embeddings for recipes\n",
    "\n",
    "## Load dataset from ./dataset/blogtext.csv\n",
    "blogset = pd.read_csv('./dataset/blogtext.csv')\n",
    "\n",
    "## Drop all columns except text\n",
    "blogset = blogset.drop(columns=['id', 'gender', 'age', 'topic', 'sign', 'date'])\n",
    "\n",
    "## Drop all rows with text length < 800 and > 1100\n",
    "blogset = blogset[blogset['text'].apply(lambda x: len(x) > 800 and len(x) < 1100)]\n",
    "\n",
    "## Keep a random sample of 20100 rows\n",
    "blogset = blogset.sample(n=20100, random_state=1)\n",
    "\n",
    "blogset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the random text embeddings\n",
    "\n",
    "print(recipes.shape[-1])\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "random_blog_embeddings = embed(blogset['text'][:recipes.shape[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a visualization of the embeddings using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Concatenate the embeddings\n",
    "pca_embeddings = np.concatenate([recipes.to:recipes.shape[-1]list(), random_blog_embeddings.numpy()], axis=0)\n",
    "\n",
    "# Create a color array\n",
    "colors = ['blue'] * train_size + ['red'] * train_size\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(pca_embeddings)\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(10, 10))\n",
    "legend = ['Recipes', 'Blog Text']\n",
    "for color in ['blue', 'red']:\n",
    "    plt.scatter([], [], c=color, label=legend.pop(0))\n",
    "plt.legend(scatterpoints=1, frameon=False, labelspacing=1, title='Embeddings')\n",
    "plt.title('PCA of Recipe embeddings compared with blog posts')\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a visualization of the embeddings using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# directions = dataset['directions']\n",
    "# average_length = sum(len(direction) for direction in directions) / len(directions)\n",
    "# print(f\"Average length of directions: {average_length}\")\n",
    "\n",
    "random_blog_embeddings = embed(blogset['text'][:train_size])\n",
    "\n",
    "# Concatenate the embeddings\n",
    "pca_embeddings = np.concatenate([train_title_embeddings.numpy(), train_ingredients_embeddings.numpy(), train_directions_embeddings.numpy(), random_blog_embeddings.numpy()], axis=0)\n",
    "\n",
    "# Create a color array\n",
    "colors = ['purple'] * train_size + ['green'] * train_size + ['orange'] * train_size + ['red'] * train_size\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(pca_embeddings)\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(10, 10))\n",
    "legend = ['Title', 'Ingredients', 'Directions', 'Blog Text']\n",
    "for color in ['purple', 'green', 'blue', 'red']:\n",
    "    plt.scatter([], [], c=color, label=legend.pop(0))\n",
    "plt.legend(scatterpoints=1, frameon=False, labelspacing=1, title='Embeddings')\n",
    "plt.title('PCA of Title, Ingredients, and Directions compared with blog posts')\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
